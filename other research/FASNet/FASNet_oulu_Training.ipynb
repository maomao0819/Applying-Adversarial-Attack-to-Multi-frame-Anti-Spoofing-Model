{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "#K.set_image_dim_ordering('th')\n",
    "tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model files.\n",
    "model_save_path = '/mnt/sdb1/zhuweilun/FASNet/weights/160_epoch60_Adamax_100_oulunpu.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# dimensions of images. (less than 224x 224)\n",
    "img_width, img_height = (160,160)\n",
    "\n",
    "# nuumber of layers to freeze\n",
    "nFreeze = 11\n",
    "\n",
    "## Replayattack ##\n",
    "train_data_dir = '/mnt/sdb1/zhuweilun/FASNet/oulu_npu/train/'\n",
    "validation_data_dir = '/mnt/sdb1/zhuweilun/FASNet/oulu_npu/valid/'\n",
    "nb_train_samples = 7192\n",
    "nb_validation_samples = 5400\n",
    "nb_epoch = 60\n",
    "\n",
    "def get_tr_vgg_model(img_width, img_height):\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape = (3,img_width,img_height))\n",
    "    \n",
    "    #freeze layers\n",
    "    for layer in model.layers[:nFreeze]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #model.summary()\n",
    "    #print(len(model.layers))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_top_layers(model):\n",
    "    \n",
    "    combine_model = Sequential()\n",
    "    combine_model.add(model)\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    combine_model.add(top_model)\n",
    "    \n",
    "    return combine_model\n",
    "\n",
    "def run_train(model):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6),\n",
    "#                 optimizer=optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    print('Model Compiled.')\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip = True,\n",
    "            fill_mode='nearest',\n",
    "            data_format=\"channels_first\")\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255, data_format=\"channels_first\")\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=100,\n",
    "            class_mode='binary')\n",
    "    \n",
    "    label_map1 = (train_generator.class_indices)\n",
    "    print(label_map1)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=100,\n",
    "            class_mode='binary')\n",
    "\n",
    "    print('\\nFine-tuning top layers...\\n')\n",
    "\n",
    "    earlyStopping = callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                           patience=15, \n",
    "                                           verbose=0, mode='auto', restore_best_weights=True)\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=5, min_lr=1e-4)\n",
    "\n",
    "    \n",
    "    model.fit(\n",
    "           train_generator,\n",
    "           callbacks=[earlyStopping, reduce_lr],\n",
    "          use_multiprocessing = False,\n",
    "           steps_per_epoch=nb_train_samples/100,\n",
    "          epochs=nb_epoch,\n",
    "           validation_data=validation_generator,\n",
    "           validation_steps=nb_validation_samples/100)\n",
    "\n",
    "\n",
    "    #model.save_weights(top_model_weights_path)\n",
    "    model.save(model_save_path)\n",
    "    \n",
    "    print('\\nDone fine-tuning, have a nice day!')\n",
    "    print(\"\\nExecution time %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512, 5, 5)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 3277313   \n",
      "=================================================================\n",
      "Total params: 17,992,001\n",
      "Trainable params: 16,256,513\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "Model Compiled.\n",
      "Found 7192 images belonging to 2 classes.\n",
      "{'attack': 0, 'real': 1}\n",
      "Found 5400 images belonging to 2 classes.\n",
      "\n",
      "Fine-tuning top layers...\n",
      "\n",
      "Epoch 1/60\n",
      "72/71 [==============================] - 35s 490ms/step - loss: 0.6854 - accuracy: 0.7967 - val_loss: 0.5149 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "72/71 [==============================] - 34s 474ms/step - loss: 0.5014 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "72/71 [==============================] - 34s 477ms/step - loss: 0.4340 - accuracy: 0.8060 - val_loss: 0.3576 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "72/71 [==============================] - 34s 474ms/step - loss: 0.3524 - accuracy: 0.8423 - val_loss: 0.3293 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "72/71 [==============================] - 34s 473ms/step - loss: 0.2920 - accuracy: 0.8704 - val_loss: 0.3029 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "72/71 [==============================] - 34s 474ms/step - loss: 0.2629 - accuracy: 0.8840 - val_loss: 0.2824 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "72/71 [==============================] - 34s 475ms/step - loss: 0.2376 - accuracy: 0.9000 - val_loss: 0.2848 - val_accuracy: 0.8726 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "72/71 [==============================] - 32s 445ms/step - loss: 0.2154 - accuracy: 0.9096 - val_loss: 0.2418 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "72/71 [==============================] - 32s 440ms/step - loss: 0.1688 - accuracy: 0.9270 - val_loss: 0.2198 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "72/71 [==============================] - 32s 441ms/step - loss: 0.1866 - accuracy: 0.9253 - val_loss: 0.2091 - val_accuracy: 0.9139 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "72/71 [==============================] - 32s 441ms/step - loss: 0.1415 - accuracy: 0.9438 - val_loss: 0.1919 - val_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "72/71 [==============================] - 32s 439ms/step - loss: 0.1587 - accuracy: 0.9360 - val_loss: 0.2156 - val_accuracy: 0.9131 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "72/71 [==============================] - 32s 441ms/step - loss: 0.1292 - accuracy: 0.9491 - val_loss: 0.2284 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "72/71 [==============================] - 32s 439ms/step - loss: 0.1152 - accuracy: 0.9562 - val_loss: 0.2579 - val_accuracy: 0.9193 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "72/71 [==============================] - 32s 443ms/step - loss: 0.1225 - accuracy: 0.9505 - val_loss: 0.2368 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "72/71 [==============================] - 32s 443ms/step - loss: 0.0962 - accuracy: 0.9629 - val_loss: 0.2421 - val_accuracy: 0.9165 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "72/71 [==============================] - 38s 527ms/step - loss: 0.0829 - accuracy: 0.9680 - val_loss: 0.2964 - val_accuracy: 0.8870 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "72/71 [==============================] - 38s 533ms/step - loss: 0.0765 - accuracy: 0.9702 - val_loss: 0.2220 - val_accuracy: 0.9202 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "72/71 [==============================] - 38s 534ms/step - loss: 0.0711 - accuracy: 0.9715 - val_loss: 0.2719 - val_accuracy: 0.9246 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "72/71 [==============================] - 39s 541ms/step - loss: 0.0734 - accuracy: 0.9690 - val_loss: 0.2022 - val_accuracy: 0.9383 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "72/71 [==============================] - 38s 530ms/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 0.1898 - val_accuracy: 0.9400 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "72/71 [==============================] - 32s 448ms/step - loss: 0.0714 - accuracy: 0.9709 - val_loss: 0.2117 - val_accuracy: 0.9433 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "72/71 [==============================] - 34s 467ms/step - loss: 0.0660 - accuracy: 0.9750 - val_loss: 0.2232 - val_accuracy: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "72/71 [==============================] - 34s 474ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.1786 - val_accuracy: 0.9474 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "72/71 [==============================] - 34s 472ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.3912 - val_accuracy: 0.8887 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "72/71 [==============================] - 34s 474ms/step - loss: 0.0485 - accuracy: 0.9826 - val_loss: 0.3422 - val_accuracy: 0.8946 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "72/71 [==============================] - 34s 476ms/step - loss: 0.0335 - accuracy: 0.9886 - val_loss: 0.2924 - val_accuracy: 0.9326 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "72/71 [==============================] - 34s 476ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.1638 - val_accuracy: 0.9570 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "72/71 [==============================] - 34s 475ms/step - loss: 0.0366 - accuracy: 0.9862 - val_loss: 0.1986 - val_accuracy: 0.9491 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "72/71 [==============================] - 34s 473ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.2857 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "72/71 [==============================] - 34s 477ms/step - loss: 0.0407 - accuracy: 0.9857 - val_loss: 0.2297 - val_accuracy: 0.9317 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "72/71 [==============================] - 34s 477ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.2191 - val_accuracy: 0.9465 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "72/71 [==============================] - 35s 480ms/step - loss: 0.0329 - accuracy: 0.9868 - val_loss: 0.2361 - val_accuracy: 0.9443 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "72/71 [==============================] - 34s 475ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 0.3219 - val_accuracy: 0.9319 - lr: 2.5000e-04\n",
      "Epoch 35/60\n",
      "72/71 [==============================] - 34s 477ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.3226 - val_accuracy: 0.9419 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "72/71 [==============================] - 34s 477ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.3141 - val_accuracy: 0.9450 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "72/71 [==============================] - 32s 442ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.2719 - val_accuracy: 0.9452 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "72/71 [==============================] - 32s 441ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.2894 - val_accuracy: 0.9424 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "72/71 [==============================] - 32s 440ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.2609 - val_accuracy: 0.9509 - lr: 1.2500e-04\n",
      "Epoch 40/60\n",
      "72/71 [==============================] - 32s 442ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.3599 - val_accuracy: 0.9350 - lr: 1.2500e-04\n",
      "Epoch 41/60\n",
      "72/71 [==============================] - 32s 441ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.2830 - val_accuracy: 0.9517 - lr: 1.2500e-04\n",
      "Epoch 42/60\n",
      "72/71 [==============================] - 32s 440ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.2972 - val_accuracy: 0.9467 - lr: 1.2500e-04\n",
      "Epoch 43/60\n",
      "72/71 [==============================] - 32s 442ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.3282 - val_accuracy: 0.9400 - lr: 1.2500e-04\n",
      "\n",
      "Done fine-tuning, have a nice day!\n",
      "\n",
      "Execution time 1479.286262512207 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    vgg16_tr_model = get_tr_vgg_model(img_width, img_height)\n",
    "    vgg16_tr_model = add_top_layers(vgg16_tr_model)\n",
    "    vgg16_tr_model.summary()\n",
    "    \n",
    "    # fine-tuning the model \n",
    "    run_train(vgg16_tr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
