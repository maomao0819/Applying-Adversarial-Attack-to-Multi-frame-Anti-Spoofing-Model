{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#K.set_image_dim_ordering('th')\n",
    "tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model files.\n",
    "model_save_path = '/mnt/sdb1/zhuweilun/FASNet/weights/160_epoch80_casia_fasd_new.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# dimensions of images. (less than 224x 224)\n",
    "img_width, img_height = (160,160)\n",
    "\n",
    "# nuumber of layers to freeze\n",
    "nFreeze = 11\n",
    "\n",
    "## Replayattack ##\n",
    "#train_data_dir = '/home/mike/FASNet/replayattack/train/'\n",
    "#validation_data_dir = '/home/mike/FASNet/replayattack/valid/'\n",
    "\n",
    "## CASIA ##\n",
    "train_data_dir = '/mnt/sdb1/zhuweilun/FASNet/casia_fasd/train/'\n",
    "nb_train_samples = 9039\n",
    "nb_epoch = 80\n",
    "\n",
    "def get_tr_vgg_model(img_width, img_height):\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape = (3,img_width,img_height))\n",
    "    \n",
    "    #freeze layers\n",
    "    for layer in model.layers[:nFreeze]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #model.summary()\n",
    "    #print(len(model.layers))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_top_layers(model):\n",
    "    \n",
    "    combine_model = Sequential()\n",
    "    combine_model.add(model)\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    #top_model.add(Dense(2, activation='softmax'))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    combine_model.add(top_model)\n",
    "    \n",
    "    return combine_model\n",
    "\n",
    "def run_train(model):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "    #model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6),\n",
    "     #         metrics=['categorical_accuracy'])\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    print('Model Compiled.')\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip = True,\n",
    "            fill_mode='nearest',\n",
    "            data_format=\"channels_first\")\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#                                       data_format=\"channels_first\")\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=200,\n",
    "            #class_mode='categorical')\n",
    "            class_mode='binary')\n",
    "    \n",
    "    label_map1 = (train_generator.class_indices)\n",
    "    print(label_map1)\n",
    "\n",
    "#     validation_generator = test_datagen.flow_from_directory(\n",
    "#             validation_data_dir,\n",
    "#             target_size=(img_height, img_width),\n",
    "#             batch_size=200,\n",
    "#             #class_mode='categorical')\n",
    "#             class_mode='binary')\n",
    "    \n",
    "    #label_map2 = (validation_generator.class_indices)\n",
    "    #print(label_map2)\n",
    "\n",
    "    print('\\nFine-tuning top layers...\\n')\n",
    "\n",
    "#     earlyStopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                            patience=10, \n",
    "#                                            verbose=0, mode='min', restore_best_weights=True)\n",
    "\n",
    "    #fit model\n",
    "    #model.fit_generator(\n",
    "    #       train_generator,\n",
    "    #       callbacks=[earlyStopping],\n",
    "    #      use_multiprocessing = False,\n",
    "    #       steps_per_epoch=nb_train_samples/100,\n",
    "    #      epochs=nb_epoch,\n",
    "    #       validation_data=validation_generator,\n",
    "    #       validation_steps=nb_validation_samples/100)\n",
    "    \n",
    "#     model.fit(\n",
    "#            train_generator,\n",
    "#            callbacks=[earlyStopping],\n",
    "#           use_multiprocessing = False,\n",
    "#            steps_per_epoch=nb_train_samples/200,\n",
    "#           epochs=nb_epoch,\n",
    "#            validation_data=validation_generator,\n",
    "#            validation_steps=nb_validation_samples/200)\n",
    "\n",
    "    model.fit(\n",
    "            train_generator,\n",
    "            use_multiprocessing = False,\n",
    "            steps_per_epoch=nb_train_samples/200,\n",
    "            epochs=nb_epoch)\n",
    "\n",
    "\n",
    "    #model.save_weights(top_model_weights_path)\n",
    "    model.save(model_save_path)\n",
    "    \n",
    "    print('\\nDone fine-tuning, have a nice day!')\n",
    "    print(\"\\nExecution time %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512, 5, 5)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 3277313   \n",
      "=================================================================\n",
      "Total params: 17,992,001\n",
      "Trainable params: 16,256,513\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "Model Compiled.\n",
      "Found 9039 images belonging to 2 classes.\n",
      "{'attack': 0, 'real': 1}\n",
      "\n",
      "Fine-tuning top layers...\n",
      "\n",
      "Epoch 1/80\n",
      "46/45 [==============================] - 43s 929ms/step - loss: 3.6996 - accuracy: 0.7554\n",
      "Epoch 2/80\n",
      "46/45 [==============================] - 43s 934ms/step - loss: 3.7065 - accuracy: 0.7597\n",
      "Epoch 3/80\n",
      "46/45 [==============================] - 43s 937ms/step - loss: 3.7065 - accuracy: 0.7597\n",
      "Epoch 4/80\n",
      "46/45 [==============================] - 43s 935ms/step - loss: 3.7065 - accuracy: 0.7597\n",
      "Epoch 5/80\n",
      "46/45 [==============================] - 43s 936ms/step - loss: 3.7065 - accuracy: 0.7597\n",
      "Epoch 6/80\n",
      "22/45 [=============>................] - ETA: 21s - loss: 3.8597 - accuracy: 0.7498"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    vgg16_tr_model = get_tr_vgg_model(img_width, img_height)\n",
    "    vgg16_tr_model = add_top_layers(vgg16_tr_model)\n",
    "    vgg16_tr_model.summary()\n",
    "    \n",
    "    # fine-tuning the model \n",
    "    run_train(vgg16_tr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
