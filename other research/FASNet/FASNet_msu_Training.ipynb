{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 11 14:49:19 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   35C    P8    10W / 280W |     62MiB / 11175MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 20%   37C    P8     7W / 250W |      2MiB / 11178MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1009      G   /usr/lib/xorg/Xorg                 59MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#K.set_image_dim_ordering('th')\n",
    "tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model files.\n",
    "model_save_path = '/mnt/sdb1/zhuweilun/FASNet/weights/160_epoch30_msu.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# dimensions of images. (less than 224x 224)\n",
    "img_width, img_height = (160,160)\n",
    "\n",
    "# nuumber of layers to freeze\n",
    "nFreeze = 11\n",
    "\n",
    "## MSU ##\n",
    "train_data_dir = '/mnt/sdb1/zhuweilun/FASNet/msu_mfsd/train/'\n",
    "nb_train_samples = 8664\n",
    "nb_epoch = 30\n",
    "\n",
    "def get_tr_vgg_model(img_width, img_height):\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape = (3,img_width,img_height))\n",
    "    \n",
    "    #freeze layers\n",
    "    for layer in model.layers[:nFreeze]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #model.summary()\n",
    "    #print(len(model.layers))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_top_layers(model):\n",
    "    \n",
    "    combine_model = Sequential()\n",
    "    combine_model.add(model)\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    #top_model.add(Dense(2, activation='softmax'))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    combine_model.add(top_model)\n",
    "    \n",
    "    return combine_model\n",
    "\n",
    "def run_train(model):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6),\n",
    "#                   optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6),\n",
    "#                 optimizer=optimizers.Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=1e-6),\n",
    "#                 optimizer=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n",
    "#                   optimizer=optimizers.Adamax(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    print('Model Compiled.')\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip = True,\n",
    "            fill_mode='nearest',\n",
    "            data_format=\"channels_first\")\n",
    "\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_height, img_width),\n",
    "            batch_size=200,\n",
    "            class_mode='binary')\n",
    "    \n",
    "    label_map1 = (train_generator.class_indices)\n",
    "    print(label_map1)\n",
    "\n",
    "\n",
    "    print('\\nFine-tuning top layers...\\n')\n",
    "\n",
    "#     earlyStopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                            patience=10, \n",
    "#                                            verbose=0, mode='min', restore_best_weights=True)\n",
    "\n",
    "    #fit model\n",
    "    #model.fit_generator(\n",
    "    #       train_generator,\n",
    "    #       callbacks=[earlyStopping],\n",
    "    #      use_multiprocessing = False,\n",
    "    #       steps_per_epoch=nb_train_samples/100,\n",
    "    #      epochs=nb_epoch,\n",
    "    #       validation_data=validation_generator,\n",
    "    #       validation_steps=nb_validation_samples/100)\n",
    "    \n",
    "#     model.fit(\n",
    "#            train_generator,\n",
    "#            callbacks=[earlyStopping],\n",
    "#           use_multiprocessing = False,\n",
    "#            steps_per_epoch=nb_train_samples/200,\n",
    "#           epochs=nb_epoch,\n",
    "#            validation_data=validation_generator,\n",
    "#            validation_steps=nb_validation_samples/200)\n",
    "\n",
    "    model.fit(\n",
    "            train_generator,\n",
    "            use_multiprocessing = False,\n",
    "            steps_per_epoch=nb_train_samples/200,\n",
    "            epochs=nb_epoch)\n",
    "\n",
    "\n",
    "    #model.save_weights(top_model_weights_path)\n",
    "    model.save(model_save_path)\n",
    "    \n",
    "    print('\\nDone fine-tuning, have a nice day!')\n",
    "    print(\"\\nExecution time %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512, 5, 5)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 3277313   \n",
      "=================================================================\n",
      "Total params: 17,992,001\n",
      "Trainable params: 16,256,513\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "Model Compiled.\n",
      "Found 8664 images belonging to 2 classes.\n",
      "{'attack': 0, 'real': 1}\n",
      "\n",
      "Fine-tuning top layers...\n",
      "\n",
      "Epoch 1/30\n",
      " 8/43 [====>.........................] - ETA: 23s - loss: 0.7213 - accuracy: 0.6381"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  OSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 243, in __call__\n    ret = func(*args)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 785, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 801, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 932, in generator_fn\n    yield x[i]\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/Image.py\", line 1903, in resize\n    self.load()\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 284, in load\n    raise_oserror(err_code)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) Unknown:  OSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 243, in __call__\n    ret = func(*args)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 785, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 801, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 932, in generator_fn\n    yield x[i]\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/Image.py\", line 1903, in resize\n    self.load()\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 284, in load\n    raise_oserror(err_code)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1836]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-466a4476e599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# fine-tuning the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_tr_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-3223ffc5fd9d>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             epochs=nb_epoch)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  OSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 243, in __call__\n    ret = func(*args)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 785, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 801, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 932, in generator_fn\n    yield x[i]\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/Image.py\", line 1903, in resize\n    self.load()\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 284, in load\n    raise_oserror(err_code)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) Unknown:  OSError: unrecognized data stream contents when reading image file\nTraceback (most recent call last):\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 243, in __call__\n    ret = func(*args)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 785, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 801, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 932, in generator_fn\n    yield x[i]\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/Image.py\", line 1903, in resize\n    self.load()\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 284, in load\n    raise_oserror(err_code)\n\n  File \"/home/zhuweilun/.conda/envs/tf2/lib/python3.6/site-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\n\nOSError: unrecognized data stream contents when reading image file\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1836]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    vgg16_tr_model = get_tr_vgg_model(img_width, img_height)\n",
    "    vgg16_tr_model = add_top_layers(vgg16_tr_model)\n",
    "    vgg16_tr_model.summary()\n",
    "    \n",
    "    # fine-tuning the model \n",
    "    run_train(vgg16_tr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
