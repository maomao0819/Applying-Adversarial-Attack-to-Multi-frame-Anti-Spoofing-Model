{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import math\n",
    "# Load Keras dependencies:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import tensorflow.keras\n",
    "tensorflow.keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Load imgaug\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "import random \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#     if gpus:\n",
    "#         try:\n",
    "#             tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])\n",
    "#             logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#             print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "#         except RuntimeError as e:\n",
    "#             # Virtual devices must be set before GPUs have been initialized\n",
    "#             print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_channel_last(image):\n",
    "    #print(type(image))\n",
    "    shape = np.shape(image)\n",
    "    if shape[-1] != 3:\n",
    "        if shape[0] == 3:\n",
    "            return np.moveaxis(image, 0, -1)\n",
    "        if shape[1] == 3:\n",
    "            return np.moveaxis(image, 1, -1)\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "## rebroadcast simulation\n",
    "seq = iaa.Sequential([\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        rotate=(-5, 5),\n",
    "        scale={\"x\": (0.85, 1.15), \"y\": (0.85, 1.15)},\n",
    "        shear=(-5, 5),\n",
    "        translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)},seed=randint(0, 1000)\n",
    "    ),\n",
    "\n",
    "    iaa.PerspectiveTransform(scale=(0, 0.025),seed=randint(0, 1000)),\n",
    "\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    # iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    #iaa.Multiply((0.85, 1.15)),\n",
    "\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.LinearContrast((0.9, 1.1),seed=randint(0, 1000)),\n",
    "    iaa.MultiplyBrightness((0.85, 1.15),seed=randint(0, 1000)),\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    # iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "    iaa.GaussianBlur(sigma=(0, 1),seed=randint(0, 1000)),\n",
    "        \n",
    "    iaa.AddToHueAndSaturation((-15, 15), per_channel=True,seed=randint(0, 1000))\n",
    "\n",
    "    # iaa.Fliplr(0.5), # horizontal flips\n",
    "    # iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "        \n",
    "    # Add gaussian noise.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "            \n",
    "], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.random as iarandom\n",
    "\n",
    "def image_augment(images):\n",
    "    images = to_channel_last(images)\n",
    "    images_augment = seq(images=images.astype(np.uint8))\n",
    "    if np.shape(images_augment)[-1] == 3:\n",
    "        images_augment = np.moveaxis(images_augment, -1, 1)\n",
    "    return images_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess_image(imgPath, img_width, img_height):\n",
    "    img = load_img(imgPath, target_size=(img_width, img_height))\n",
    "    imgArray = img_to_array(img)\n",
    "    imgArray = imgArray.reshape(1, 3, img_width, img_height)\n",
    "    # img_aug = image_augment(imgArray)\n",
    "    imgArray = imgArray / float(255)\n",
    "    # imgArray_list = []\n",
    "    # for _ in range(2000):\n",
    "    #     img_aug = image_augment(imgArray)\n",
    "    #     img_aug = img_aug / float(255)\n",
    "    #     imgArray_list.append(img_aug)\n",
    "    # imgArray = imgArray_list[0]\n",
    "    return imgArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def origin_succes_rate(data_dir, img_width, img_height, model):\n",
    "    total_attack = 0\n",
    "    success_cnt = 0\n",
    "    for image_name in os.listdir(data_dir):\n",
    "        print(\"image_name \", image_name)\n",
    "        filename = os.path.join(data_dir, image_name)\n",
    "        img = read_preprocess_image(filename, img_width, img_height)\n",
    "        outLabel = (model.predict(img) > 0.5).astype(\"int32\")\n",
    "        total_attack += 1\n",
    "        if outLabel == 0:\n",
    "            success_cnt += 1\n",
    "    if success_cnt:\n",
    "        if total_attack > 0:\n",
    "            success_rate = success_cnt / total_attack\n",
    "            print(f'accuracy: {100 * success_rate:.2f}%')\n",
    "        else:\n",
    "            print(f'accuracy: {100:.2f}%')\n",
    "    else:\n",
    "        print(f'accuracy: {0:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fix(prediction, is_prediction_fix):\n",
    "    # if np.array(prediction) <= 1e-9:\n",
    "    #     prediction += 1e-9\n",
    "    while np.array(prediction) <= 1e-7:\n",
    "        prediction *= 10\n",
    "        is_prediction_fix = True\n",
    "    return prediction, is_prediction_fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_pattern(input_image, input_label, model):\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "    is_prediction_fix = False\n",
    "    cnt = 0\n",
    "    total_loss = 0.0\n",
    "    iterations = 500\n",
    "    \n",
    "    total_gradient = tf.zeros([1, 3, 160, 160], tf.float64)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        cnt += 1\n",
    "        img_aug = image_augment(input_image * float(255)) / float(255)\n",
    "        img_aug = tf.convert_to_tensor(img_aug)\n",
    "        #print(cnt)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(img_aug)\n",
    "            prediction = model(img_aug)\n",
    "            # print(\"pred \", np.array(prediction[0]))\n",
    "            prediction, is_prediction_fix = prediction_fix(prediction, is_prediction_fix)\n",
    "            loss = loss_object(input_label, prediction)\n",
    "        total_gradient += tape.gradient(loss, img_aug)\n",
    "        #print(total_gradient)\n",
    "    avg_gradient = total_gradient / iterations\n",
    "    \n",
    "    \n",
    "    #print(total_loss)\n",
    "    #avg_loss = total_loss / iterations\n",
    "    #total_loss = loss + 0.15\n",
    "    #gradient = tape.gradient(loss, input_image)\n",
    "    #print(\"grad \", avg_gradient)\n",
    "    signed_grad = tf.sign(avg_gradient)\n",
    "    return signed_grad, is_prediction_fix\n",
    "\n",
    "# def create_adversarial_pattern(input_image, input_label, model):\n",
    "#     loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "#     is_prediction_fix = False\n",
    "#     cnt = 0\n",
    "#     total_loss = 0.0\n",
    "#     iterations = 10\n",
    "    \n",
    "#     #total_gradient = tf.zeros([1, 3, 160, 160], tf.float64)\n",
    "    \n",
    "#     for _ in range(iterations):\n",
    "#         cnt += 1\n",
    "#         img_aug = image_augment(input_image * float(255)) / float(255)\n",
    "#         img_aug = tf.convert_to_tensor(img_aug)\n",
    "#         #print(cnt)\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(img_aug)\n",
    "#             prediction = model(img_aug)\n",
    "#             # print(\"pred \", np.array(prediction[0]))\n",
    "#             prediction, is_prediction_fix = prediction_fix(prediction, is_prediction_fix)\n",
    "#             loss = loss_object(input_label, prediction)\n",
    "#         #total_gradient += tape.gradient(loss, img_aug)\n",
    "#         #print(\"loss: \")\n",
    "#         #print(loss)\n",
    "#         total_loss += loss\n",
    "#         #print(\"total: \")\n",
    "#         #print(total_loss)\n",
    "#     #avg_gradient = total_gradient / iterations\n",
    "    \n",
    "#     #print(total_loss)\n",
    "#     avg_loss = total_loss / iterations\n",
    "#     print(type(avg_loss))\n",
    "#     avg_loss = tf.Variable(avg_loss)\n",
    "#     print(type(avg_loss))\n",
    "#     #total_loss = loss + 0.15\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         gradient = tape.gradient(avg_loss, input_image)\n",
    "#         #print(gradient)\n",
    "#     #gradient = tf.gradients(avg_loss, input_image)\n",
    "    \n",
    "#     #print(\"grad \", avg_gradient)\n",
    "#     #signed_grad = tf.sign(avg_gradient)\n",
    "#     signed_grad = tf.sign(gradient)\n",
    "#     return signed_grad, is_prediction_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@tf.function\n",
    "# def create_adversarial_pattern(input_image, input_label, model):\n",
    "#     loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "#     is_prediction_fix = False\n",
    "#     cnt = 0\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(input_image)\n",
    "#         prediction = model(input_image)\n",
    "#         # print(\"pred \", np.array(prediction[0]))\n",
    "#         prediction, is_prediction_fix = prediction_fix(prediction, is_prediction_fix)\n",
    "#         loss = loss_object(input_label, prediction)\n",
    "        \n",
    "#         for _ in range(799):\n",
    "#             cnt += 1\n",
    "#             img_aug = image_augment(input_image * float(255)) / float(255)\n",
    "#             prediction = model(img_aug)\n",
    "#             prediction, _ = prediction_fix(prediction, is_prediction_fix)\n",
    "#             # print('prediction ', prediction)\n",
    "#             loss += loss_object(input_label, prediction)\n",
    "#             print(cnt)\n",
    "#         print(\"loss \", loss)\n",
    "#         loss /= 800\n",
    "#     gradient = tape.gradient(loss, input_image)\n",
    "#     # print(\"grad \", gradient)\n",
    "#     signed_grad = tf.sign(gradient)\n",
    "#     return signed_grad, is_prediction_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def perturbations(image, index, model):\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    # image_probs = model.predict(image)\n",
    "    # label = tf.one_hot(index, 2)\n",
    "    # label = tf.reshape(label, (1, 2))\n",
    "    label = tf.convert_to_tensor(index)\n",
    "    return create_adversarial_pattern(image, label, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbations_t(perturbations):\n",
    "    return tf.transpose(perturbations, perm = [0, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def fgsm(image, eps, model):\n",
    "    perturbation, is_prediction_fix = perturbations(image, 0, model)\n",
    "    #print(eps*perturbation)\n",
    "    return image + eps * perturbation, is_prediction_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_0_1(origin_image_np, adv_x, eps):\n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    adv_x = tf.clip_by_value(adv_x, origin_image_np - eps, origin_image_np + eps)\n",
    "    return tf.convert_to_tensor(adv_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm_0_1(origin_image, eps, model):\n",
    "    if eps > 1:\n",
    "        iteration_time_N = min(eps + 4, 1.25 * eps)\n",
    "    elif eps > 0:\n",
    "        iteration_time_N = min(eps * 255 + 4, 1.25 * eps * 255)\n",
    "    else:\n",
    "        iteration_time_N = 0\n",
    "    int_iteration_time_N = np.round(iteration_time_N, decimals=0).astype(np.int32)\n",
    "    # int_iteration_time_N = 5\n",
    "    if int_iteration_time_N:\n",
    "        weight_alpha = eps / int_iteration_time_N\n",
    "    adv_x = origin_image\n",
    "    origin_image_np = np.array(origin_image)\n",
    "    is_prediction_fix = False\n",
    "    for _ in range(int_iteration_time_N):\n",
    "        perturbation, is_prediction_fix_tmp = perturbations(adv_x, 0, model)\n",
    "        if is_prediction_fix_tmp:\n",
    "            is_prediction_fix = True\n",
    "        adv_x = clip_0_1(origin_image_np, adv_x + weight_alpha * perturbation, eps)\n",
    "    return adv_x, is_prediction_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def label_confidence_image(image, model):\n",
    "    #print(type(image))\n",
    "    #print(image.shape)\n",
    "    image_copy = image\n",
    "    image_probs = model.predict(image_copy)\n",
    "    label = (image_probs > 0.5).astype(\"int32\")\n",
    "    confidence = np.amax(image_probs)\n",
    "    img = np.array(image_copy)\n",
    "    img = np.moveaxis(img, 1, -1)\n",
    "    img = img[0]\n",
    "    return label, confidence, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckDirectory(path_save):\n",
    "    if not os.path.exists(path_save):\n",
    "        pathlib.Path(path_save).mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    if len(np.shape(img1)) == 4:\n",
    "        img1 = np.squeeze(img1, axis=0)\n",
    "    if len(np.shape(img2)) == 4:\n",
    "        img2 = np.squeeze(img2, axis=0)\n",
    "    if np.shape(img1)[0] == 3:\n",
    "        img1 = np.moveaxis(img1, 0, -1)\n",
    "    if np.shape(img2)[0] == 3:\n",
    "        img2 = np.moveaxis(img2, 0, -1)\n",
    "    mse = np.mean((img1 - img2) ** 2) * 255 * 255\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    psnr = 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## identity\n",
    "# def anti_spoofing_attack(name_list, data_dir, dirs, img_width, img_height, model, epsilons, path_save):\n",
    "#     idx = 0\n",
    "#     not_attack = 0\n",
    "#     attack_success = 0\n",
    "#     attack_fail = 0\n",
    "#     psnr_fail_first = 0\n",
    "#     CheckDirectory(path_save)\n",
    "#     CheckDirectory(os.path.join(path_save, dirs))\n",
    "#     for img_name in name_list:\n",
    "#         idx += 1\n",
    "#         image_dir = os.path.join(data_dir, dirs, img_name)\n",
    "#         print(image_dir)\n",
    "#         test_img = read_preprocess_image(image_dir, img_width, img_height)\n",
    "#         label, confidence, adv_x = label_confidence_image(test_img, model)\n",
    "#         if label == 1:\n",
    "#             not_attack += 1\n",
    "#             # plt.imsave(os.path.join(path_save, dirs, f\"adversarial_example_no_attack_confidence_{str(confidence)}.png\"), adv_x)\n",
    "#             print(str(idx))\n",
    "#             print(\"not_attack: \", not_attack)\n",
    "#             print(\"attack_success: \", attack_success)\n",
    "#             print(\"attack_fail: \", attack_fail)\n",
    "#             print(\"psnr_fail_first: \", psnr_fail_first)\n",
    "#             continue\n",
    "#         label = 0\n",
    "#         optimize_confidence = 0\n",
    "#         optimize_eps = 0\n",
    "#         optimize_adv = test_img\n",
    "#         for eps in epsilons:\n",
    "#             #adv_x, is_prediction_fix = ifgsm_0_1(test_img, eps, model)\n",
    "#             adv_x, is_prediction_fix = fgsm(test_img, eps, model)\n",
    "#             adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "#             # label = display_images(adv_x, descriptions[i], model)\n",
    "#             label, confidence, adv_x = label_confidence_image(adv_x, model)\n",
    "#             print(\"eps \", eps, \"confidence \", confidence)\n",
    "#             if confidence > optimize_confidence:\n",
    "#                 (optimize_confidence, optimize_eps, optimize_adv) = (confidence, eps, adv_x)\n",
    "#         is_prediction_fix_str = \"\"\n",
    "#         if is_prediction_fix:\n",
    "#             is_prediction_fix_str += \"_prediction_fix\"\n",
    "#         if optimize_confidence < 0.5:\n",
    "#             attack_fail += 1\n",
    "#             plt.imsave(os.path.join(path_save, dirs, f\"adversarial_example_{img_name[:-4]}_attack_fail{is_prediction_fix_str}.png\"), optimize_adv)\n",
    "#         else:\n",
    "#             attack_success += 1\n",
    "# #             is_psnr_pass_first = True\n",
    "# #             psnr_str = ''\n",
    "# #             print('PSNR ', calculate_psnr(test_img, optimize_adv))\n",
    "# #             while calculate_psnr(test_img, optimize_adv) < 20 or optimize_confidence < 0.5:\n",
    "# #                 is_psnr_pass_first = False\n",
    "# #                 optimize_eps /= 0.9\n",
    "# #                 adv_x = fgsm(test_img, optimize_eps, model)\n",
    "# #                 adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "# #                 label, optimize_confidence, optimize_adv = label_confidence_image(adv_x, model)\n",
    "# #             if not is_psnr_pass_first:\n",
    "# #                 psnr_str = '_psnr_fail_first'\n",
    "# #                 psnr_fail_first += 1\n",
    "#             plt.imsave(os.path.join(path_save, dirs, f\"adversarial_example_{img_name[:-4]}_eps_{str(optimize_eps)}_confidence_{str(optimize_confidence)}{psnr_str}{is_prediction_fix_str}.png\"), optimize_adv)\n",
    "#         print(str(idx))\n",
    "#         print(\"not_attack: \", not_attack)\n",
    "#         print(\"attack_success: \", attack_success)\n",
    "#         print(\"attack_fail: \", attack_fail)\n",
    "#         print(\"psnr_fail_first: \", psnr_fail_first)\n",
    "#     attack_success_rate = 0\n",
    "#     if (attack_success + attack_fail + not_attack) > 0:\n",
    "#         attack_success_rate = attack_success / (attack_success + attack_fail + not_attack)\n",
    "#         print(\"attack_success_rate: \", attack_success_rate)\n",
    "#     elif attack_success:\n",
    "#         attack_success_rate = 100\n",
    "#         print(\"attack_success_rate: 100\")\n",
    "#     else:\n",
    "#         print(\"attack_success_rate: 0\")\n",
    "#     f = open(os.path.join(path_save, \"attack success rate.txt\"), \"a\")\n",
    "#     f.write(f\"{dirs} :  {str(attack_success_rate)}\\n\")\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def anti_spoofing_attack(name_list, data_dir, img_width, img_height, model, epsilons, path_save):\n",
    "    idx = 0\n",
    "    not_attack = 0\n",
    "    attack_success = 0\n",
    "    attack_fail = 0\n",
    "    psnr_fail_first = 0\n",
    "    CheckDirectory(path_save)\n",
    "    \n",
    "    for img_name in name_list:\n",
    "        idx += 1\n",
    "        image_dir = os.path.join(data_dir, img_name)\n",
    "        print(image_dir)\n",
    "        test_img = read_preprocess_image(image_dir, img_width, img_height)\n",
    "        label, confidence, adv_x = label_confidence_image(test_img, model)\n",
    "        if label == 1:\n",
    "            not_attack += 1\n",
    "            # plt.imsave(os.path.join(path_save, dirs, f\"adversarial_example_no_attack_confidence_{str(confidence)}.png\"), adv_x)\n",
    "            print(str(idx))\n",
    "            print(\"not_attack: \", not_attack)\n",
    "            print(\"attack_success: \", attack_success)\n",
    "            print(\"attack_fail: \", attack_fail)\n",
    "            print(\"psnr_fail_first: \", psnr_fail_first)\n",
    "            continue\n",
    "            \n",
    "        label = 0\n",
    "        optimize_confidence = 0\n",
    "        optimize_eps = 0\n",
    "        optimize_adv = test_img\n",
    "        for eps in epsilons:\n",
    "            #adv_x, is_prediction_fix = ifgsm_0_1(test_img, eps, model)\n",
    "            adv_x, is_prediction_fix = fgsm(test_img, eps, model)\n",
    "            while(calculate_psnr(test_img,adv_x) < 35):\n",
    "                adv_x, is_prediction_fix = fgsm(test_img, eps, model)\n",
    "                print(calculate_psnr(test_img,adv_x))\n",
    "            adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "            # label = display_images(adv_x, descriptions[i], model)\n",
    "            label, confidence, adv_x = label_confidence_image(adv_x, model)\n",
    "            print(\"eps \", eps, \"confidence \", confidence)\n",
    "            if confidence > optimize_confidence:\n",
    "                (optimize_confidence, optimize_eps, optimize_adv) = (confidence, eps, adv_x)\n",
    "        \n",
    "        is_prediction_fix_str = \"\"\n",
    "        if is_prediction_fix:\n",
    "            is_prediction_fix_str += \"_prediction_fix\"\n",
    "        if optimize_confidence < 0.5:\n",
    "            attack_fail += 1\n",
    "            #plt.imsave(os.path.join(path_save, f\"adversarial_example_{img_name[:-4]}_attack_fail{is_prediction_fix_str}.png\"), optimize_adv)\n",
    "        else:\n",
    "            attack_success += 1\n",
    "#             is_psnr_pass_first = True\n",
    "            psnr_str = ''\n",
    "#             print('PSNR ', calculate_psnr(test_img, optimize_adv))\n",
    "#             while calculate_psnr(test_img, optimize_adv) < 20 or optimize_confidence < 0.5:\n",
    "#                 is_psnr_pass_first = False\n",
    "#                 optimize_eps /= 0.9\n",
    "#                 adv_x = fgsm(test_img, optimize_eps, model)\n",
    "#                 adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "#                 label, optimize_confidence, optimize_adv = label_confidence_image(adv_x, model)\n",
    "#             if not is_psnr_pass_first:\n",
    "#                 psnr_str = '_psnr_fail_first'\n",
    "#                 psnr_fail_first += 1\n",
    "            plt.imsave(os.path.join(path_save, f\"adversarial_example_{img_name[:-4]}_eps_{str(optimize_eps)}_confidence_{str(optimize_confidence)}{psnr_str}{is_prediction_fix_str}.png\"), optimize_adv)\n",
    "        print(str(idx))\n",
    "        print(\"not_attack: \", not_attack)\n",
    "        print(\"attack_success: \", attack_success)\n",
    "        print(\"attack_fail: \", attack_fail)\n",
    "\n",
    "        print(\"psnr_fail_first: \", psnr_fail_first)\n",
    "    attack_success_rate = 0\n",
    "    if (attack_success + attack_fail + not_attack) > 0:\n",
    "        attack_success_rate = attack_success / (attack_success + attack_fail + not_attack)\n",
    "        print(\"attack_success_rate: \", attack_success_rate)\n",
    "    elif attack_success:\n",
    "        attack_success_rate = 100\n",
    "        print(\"attack_success_rate: 100\")\n",
    "    else:\n",
    "        print(\"attack_success_rate: 0\")\n",
    "    f = open(os.path.join(path_save, \"attack success rate.txt\"), \"a\")\n",
    "    f.write(f\"{str(attack_success_rate)}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512, 5, 5)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 3277313   \n",
      "=================================================================\n",
      "Total params: 17,992,001\n",
      "Trainable params: 16,256,513\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "/home/mike/FASNet/replayattack/homemade/morphing_test_split_0.15/test/homemade_choose/1826.png\n",
      "26.020599913279625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-eee504e2cc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mepsilons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mimg_name_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0manti_spoofing_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-beec5ad3dc1a>\u001b[0m in \u001b[0;36manti_spoofing_attack\u001b[0;34m(name_list, data_dir, img_width, img_height, model, epsilons, path_save)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fa184011859a>\u001b[0m in \u001b[0;36mfgsm\u001b[0;34m(image, eps, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@tf.function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturbations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(eps*perturbation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b3c6eba46be5>\u001b[0m in \u001b[0;36mperturbations\u001b[0;34m(image, index, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# label = tf.reshape(label, (1, 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_adversarial_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-88665e5922b4>\u001b[0m in \u001b[0;36mcreate_adversarial_pattern\u001b[0;34m(input_image, input_label, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print(\"pred \", np.array(prediction[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_prediction_fix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0mTensor\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m   4438\u001b[0m     \u001b[0mclip_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(features, name)\u001b[0m\n\u001b[1;32m  10349\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m  10350\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10351\u001b[0;31m         features)\n\u001b[0m\u001b[1;32m  10352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10353\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('bsize128_homemade.h5')\n",
    "\n",
    "if model_path:\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    print('Could not load model!')\n",
    "opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#img_width, img_height = (96, 96)\n",
    "img_width, img_height = (160, 160)\n",
    "\n",
    "name_list = []\n",
    "# data_dir = \"anti-spoofing test attack image/\"\n",
    "data_dir = '/home/mike/FASNet/replayattack/homemade/morphing_test_split_0.15/test/homemade_choose'\n",
    "path_save = \"fgsm_500iter_0.05_psnr\"\n",
    "if os.path.exists(os.path.join(path_save, \"attack success rate.txt\")):\n",
    "    os.remove(os.path.join(path_save, \"attack success rate.txt\"))\n",
    "\n",
    "## identity\n",
    "# for dirs in os.listdir(data_dir):\n",
    "#     if os.path.isdir(os.path.join(data_dir, dirs)):\n",
    "#         print(\"dir \", dirs)\n",
    "#         if int(dirs.split('_')[2]) > 100:\n",
    "#             # origin_succes_rate(os.path.join(data_dir, dirs), img_width, img_height, model)\n",
    "#             # fgsm_epsilons = [0.03, 0.04]\n",
    "#             epsilons = [0.1]\n",
    "#             # ifgsm_epsilons = [i * 0.01 for i in range(10)]\n",
    "#             img_name_list = os.listdir(os.path.join(data_dir, dirs))\n",
    "#             anti_spoofing_attack(img_name_list, data_dir, dirs, img_width, img_height, model, epsilons, path_save)\n",
    "\n",
    "epsilons = [0.05]\n",
    "img_name_list = os.listdir(data_dir)\n",
    "anti_spoofing_attack(img_name_list, data_dir, img_width, img_height, model, epsilons, path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
